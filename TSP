import numpy as np
import yfinance as yf
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from kerastuner.tuners import RandomSearch
from kerastuner import HyperParameters
import pandas as pd
import matplotlib.pyplot as plt
import json

# Select a stock and gather data
def download_stock_data(stock_symbol, start_date, end_date):
    data = yf.download(stock_symbol, start=start_date, end=end_date)['Close'].values.reshape(-1, 1)
    return data

# Data Preprocessing
def preprocess_data(data):
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_scaled = scaler.fit_transform(data)
    return scaler, data_scaled

# Prepare data for LSTM
def prepare_lstm_data(data_scaled, look_back):
    X, y = [], []
    for i in range(len(data_scaled) - look_back):
        X.append(data_scaled[i:i + look_back, 0])
        y.append(data_scaled[i + look_back, 0])
    X, y = np.array(X), np.array(y)
    X = X.reshape(X.shape[0], X.shape[1], 1)
    return X, y

# Define the LSTM Model
def create_lstm_model(input_shape, hp):
    model = Sequential()
    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32), 
                   input_shape=input_shape, 
                   activation='relu', 
                   return_sequences=True))
    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))
    
    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32), 
                   activation='relu', 
                   return_sequences=True))
    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))
    
    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32), 
                   activation='relu'))
    model.add(Dropout(rate=hp.Float('dropout_3', min_value=0.0, max_value=0.5, step=0.1)))
    
    model.add(Dense(units=1))
    
    return model

# Use optimizer and compile the model
def compile_model(model):
    optimizer = Adam(learning_rate=0.001)
    model.compile(loss='mean_squared_error', optimizer=optimizer)

# Time-based Data Splitting
def split_data(X, y, train_size):
    X_train, X_val = X[:train_size], X[train_size:]
    y_train, y_val = y[:train_size], y[train_size:]
    return X_train, X_val, y_train, y_val

# Model Training with Early Stopping and Learning Rate Scheduling
def train_model(model, X_train, y_train, X_val, y_val, epochs, batch_size):
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)
    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val),
                        callbacks=[reduce_lr, early_stop, model_checkpoint], verbose=1)
    return history

# Forecasting Future Prices
def forecast_prices(best_model, scaler, data_scaled, look_back):
    last_look_back_days = data_scaled[-look_back:]
    forecast_input = last_look_back_days.reshape(1, look_back, 1)
    forecasted_price_scaled = best_model.predict(forecast_input)
    forecasted_price = scaler.inverse_transform(forecasted_price_scaled)[0][0]
    return forecasted_price

def plot_training_history(history):
    # Plot training & validation loss values
    plt.figure(figsize=(12, 6))
    plt.plot(history.history['loss'], label='Training Loss', color='blue')
    plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.show()

def load_configuration(file_path):
    with open(file_path, 'r') as config_file:
        config = json.load(config_file)
    return config

#Hyperparameter Tuning
def tune_hyperparameters(X_train, y_train, X_val, y_val):
    def build_model(hp):
        model = create_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]), hp=hp)
        compile_model(model)
        return model

    tuner = RandomSearch(
        build_model,
        objective='val_loss',
        max_trials=15,  
        directory='hyperparameter_tuning',
        project_name='stock_price_forecasting'
    )

    tuner.search(X_train, y_train, epochs=75, validation_data=(X_val, y_val))
    
    # Get the best hyperparameters
    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
    
    return best_hps
# Main function
def main():
    config = load_configuration('TSP.json')

    stock_symbol = config["stock_symbol"]
    start_date = config["start_date"]
    end_date = config["end_date"]
    look_back = config["look_back"]
    epochs = config["epochs"]
    batch_size = config["batch_size"]
    learning_rate = config["learning_rate"]
    data = download_stock_data(stock_symbol, start_date, end_date)

    # Data Preprocessing
    scaler, data_scaled = preprocess_data(data)


    # Prepare data for LSTM
    X, y = prepare_lstm_data(data_scaled, look_back)
    train_size = int(0.8 * len(X))
    X_train, X_val, y_train, y_val = split_data(X, y, train_size)

    #find best hps    
    best_hps = tune_hyperparameters(X_train, y_train, X_val, y_val)

    # Define the LSTM Model
    model = create_lstm_model(input_shape=(X.shape[1], X.shape[2]), hp=best_hps)

    # Use optimizer and compile the model
    compile_model(model)

    # Time-based Data Splitting
    best_model = create_lstm_model(hp=best_hps, input_shape=(X.shape[1], X.shape[2]))
    compile_model(best_model)
    history = train_model(best_model, X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)
    plot_training_history(history)
    # Forecasting Future Prices
    forecasted_price = forecast_prices(best_model, scaler, data_scaled, look_back)

    # Print the current value of the day entered (end date)
    current_value = data[-1][0]
    print(f"Current value for {end_date}: {current_value:.2f}")
    print(f"Forecasted price for the next day: {forecasted_price:.2f}")

    #Plot the Estimated Prices for each day in the validation set
    forecasted_prices_scaled = best_model.predict(X_val)
    forecasted_prices = scaler.inverse_transform(forecasted_prices_scaled).flatten()
    actual_prices = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
    date_range_val = pd.date_range(start=end_date, periods=len(y_val) + 1)
    data_tableau = pd.DataFrame({'Date': date_range_val[1:], 'Actual Prices': actual_prices, 'Forecasted Prices': forecasted_prices})
    data_tableau.to_csv('tableau_TSP.csv', index=False)
    plt.figure(figsize=(12, 6))
    plt.plot(date_range_val[1:], actual_prices, label='Actual Prices', color='blue')
    plt.plot(date_range_val[1:], forecasted_prices, label='Forecasted Prices', color='red')
    plt.title('Actual vs. Forecasted Prices')
    plt.xlabel('Date')
    plt.ylabel('Stock Price')
    plt.legend()
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    main()








